{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0f24299762166d4dc4fa7eff9bccacc2d360c88a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "89b39cf794f49dfdb8ee2aa8ec096577cd0213e1",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train...\n",
      "loading test\n",
      "concat dfs\n"
     ]
    }
   ],
   "source": [
    "text_cols = ['param_1','param_2','param_3','title','description']\n",
    "print('loading train...')\n",
    "train = pd.read_csv('../train.csv', index_col = 'item_id', usecols = text_cols + ['item_id','image_top_1'])\n",
    "train_indices = train.index\n",
    "print('loading test')\n",
    "test = pd.read_csv('../test.csv', index_col = 'item_id', usecols = text_cols + ['item_id','image_top_1'])\n",
    "test_indices = test.index\n",
    "print('concat dfs')\n",
    "df = pd.concat([train,test])\n",
    "nan_indices = df[pd.isnull(df['image_top_1'])].index\n",
    "not_nan_indices = df[pd.notnull(df['image_top_1'])].index\n",
    "\n",
    "#df = df[pd.notnull(df['image_top_1'])]\n",
    "\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca25a8d6009a3e6bf0d0d96e98342c2281a92ef5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('cleaning text')\n",
    "\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].fillna('nan').astype(str)\n",
    "print('concat text')\n",
    "df['text'] = df[text_cols].apply(lambda x: ' '.join(x), axis=1)\n",
    "df.drop(text_cols,axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c0db8c620112d43f8c7e10ef3819985b110868e6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_features = 100000 # max amount of words considered\n",
    "max_len = 100 #maximum length of text\n",
    "dim = 100 #dimension of embedding\n",
    "\n",
    "\n",
    "print('tokenizing...',end='')\n",
    "tic = time.time()\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(df['text'].values))\n",
    "toc = time.time()\n",
    "print('done. {}'.format(toc-tic))\n",
    "\n",
    "col = 'text'\n",
    "print(\"   Transforming {} to seq...\".format(col))\n",
    "tic = time.time()\n",
    "df[col] = tokenizer.texts_to_sequences(df[col])\n",
    "toc = time.time()\n",
    "print('done. {}'.format(toc-tic))\n",
    "\n",
    "print('padding X_train')\n",
    "tic = time.time()\n",
    "X_train = pad_sequences(df.loc[not_nan_indices,col], maxlen=max_len)\n",
    "toc = time.time()\n",
    "print('done. {}'.format(toc-tic))\n",
    "\n",
    "print('padding X_nan')\n",
    "tic = time.time()\n",
    "X_nan = pad_sequences(df.loc[nan_indices,col], maxlen=max_len)\n",
    "toc = time.time()\n",
    "print('done. {}'.format(toc-tic))\n",
    "\n",
    "df.drop(['text'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7303884e216a21b4eed2b35b9d833e9a70a1fa1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.loc[not_nan_indices,'image_top_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input,PReLU,BatchNormalization, GlobalMaxPooling1D, GlobalAveragePooling1D, CuDNNGRU, Bidirectional, Dense, Embedding\n",
    "from keras.layers import Concatenate, Flatten, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import he_uniform\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "from keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n",
    "\n",
    "\n",
    "\n",
    "def all_pool(tensor):\n",
    "    avg_tensor = GlobalAveragePooling1D()(tensor)\n",
    "    max_tensor = GlobalMaxPooling1D()(tensor)\n",
    "    res_tensor = Concatenate()([avg_tensor, max_tensor])\n",
    "    return res_tensor\n",
    "\n",
    "def build_model():\n",
    "    inp = Input(shape=(max_len,))\n",
    "\n",
    "    embedding = Embedding(max_features + 1, dim)(inp)\n",
    "    x = Bidirectional(CuDNNGRU(64,return_sequences=True))(embedding)\n",
    "    x = all_pool(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation = 'relu')(x)\n",
    "    out = Dense(3067, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.0005), loss=sparse_categorical_crossentropy)\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "63decdebd8fd260ae7b78986bb223b08a4baf50a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=2)\n",
    "check_point = ModelCheckpoint('model.hdf5', monitor = \"val_loss\", mode = \"min\", save_best_only = True, verbose = 1)\n",
    "\n",
    "history = model.fit(X_train, y, batch_size = 512, epochs = 10,\n",
    "                verbose = 1, validation_split=0.1,callbacks=[early_stop,check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word = {tokenizer.word_index[word]:word for word in tokenizer.word_index}\n",
    "weights = model.layers[1].get_weights()[0]\n",
    "embedding_dict = {}\n",
    "for id in id2word:\n",
    "    if id <= weights.shape[0]-1:\n",
    "        embedding_dict[id2word[id]] = weights[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6121bb88f97787035321a4ac1de25d722e6cefca",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('embedding_dict.p','wb') as f:\n",
    "    pickle.dump(embedding_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "cd90226f2e93432d0de4be437c4c35de2b22931e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_nan,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "f92a5d24f4906e05b3c12355abdc97a73c040ea4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 0\n",
    "classes = np.zeros(shape=np.argmax(preds,axis = 1).shape)\n",
    "for i in range(preds.shape[0]):\n",
    "    if np.max(preds[i]) > 0.1:\n",
    "        k+=1\n",
    "        classes[i] = np.argmax(preds[i])\n",
    "    else:\n",
    "        classes[i] = np.nan\n",
    "df.loc[nan_indices,'image_top_1'] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b59be2f86330eecc80c8b032b9cf38bba39a93b6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[train_indices].to_csv('train_image_top_1_features.csv')\n",
    "df.loc[test_indices].to_csv('test_image_top_1_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
